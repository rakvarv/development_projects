{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below we are referencing the dataset and doing some very basic pre-processing to make our data look better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nyc-rolling-sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reason for dropping EASE-MENT and Unnamed: 0\n",
    "The column EASE-MENT is dropped because it is completely and does not serve any value in the prediction of house prices. \n",
    "\n",
    "We are dropping Unnamed: 0 as it seems to be an iterator and serves no real purpose in predicting house prices, it seems to  equate to AmountOfRows(x), x being the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping column as it is empty\n",
    "del df['EASE-MENT']\n",
    "#Dropping as it looks like an iterator\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "del df['SALE DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicated entries\n",
    "sum(df.duplicated(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are we removing duplicate values?\n",
    "The reason we are removing the duplicates is because we are trying to avoid potential overfitting that might or might not be because of those duplicate values. but is not guaranteed as it just adds more weight to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the duplicates and check that it worked\n",
    "\n",
    "df = df.drop_duplicates(df.columns, keep='last')\n",
    "sum(df.duplicated(df.columns))\n",
    "\n",
    "# Current duplicate values after removal: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onverting some of the columns to appropriate datatype\n",
    "\n",
    "df['TAX CLASS AT TIME OF SALE'] = df['TAX CLASS AT TIME OF SALE'].astype('category')\n",
    "df['TAX CLASS AT PRESENT'] = df['TAX CLASS AT PRESENT'].astype('category')\n",
    "df['LAND SQUARE FEET'] = pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce')\n",
    "df['GROSS SQUARE FEET']= pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\n",
    "#df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], errors='coerce')\n",
    "df['SALE PRICE'] = pd.to_numeric(df['SALE PRICE'], errors='coerce')\n",
    "df['BOROUGH'] = df['BOROUGH'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LAND SQUARE FEET', 'GROSS SQUARE FEET', 'SALE PRICE'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing values\n",
    "\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SALE PRICE           0.167196\n",
       "LAND SQUARE FEET     0.312213\n",
       "GROSS SQUARE FEET    0.327888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organizing the columns with missing values including its values\n",
    "\n",
    "miss=df.isnull().sum()/len(df)\n",
    "miss=miss[miss>0]\n",
    "miss.sort_values(inplace=True)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SALE PRICE</th>\n",
       "      <td>0.167196</td>\n",
       "      <td>SALE PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <td>0.312213</td>\n",
       "      <td>LAND SQUARE FEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <td>0.327888</td>\n",
       "      <td>GROSS SQUARE FEET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count               Name\n",
       "Name                                          \n",
       "SALE PRICE         0.167196         SALE PRICE\n",
       "LAND SQUARE FEET   0.312213   LAND SQUARE FEET\n",
       "GROSS SQUARE FEET  0.327888  GROSS SQUARE FEET"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing the same as previous box, but with better aesthetics. \n",
    "\n",
    "miss=miss.to_frame()\n",
    "miss.columns=['count']\n",
    "miss.index.names=['Name']\n",
    "miss['Name']=miss.index\n",
    "miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why fill up the columns?\n",
    "All these missing values can be data corruption or failure to record data. To handle these different missing data is a very important part of the pre-processing. Including, many machine-learning algorithms do not support all these missing values, and therefor needs to be delt with. And the way we choose to deal with them, is get the mean value of the column, and replace the missing values with that average value. Deleting all the rows that are missing values can cause detrimental changes to the prediction of the algorithms, and in worst case scenario make it predict a lot worse than it could have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIlling up columns with mean value to replace the missing values.\n",
    "df['LAND SQUARE FEET']=df['LAND SQUARE FEET'].fillna(df['LAND SQUARE FEET'].mean())\n",
    "df['GROSS SQUARE FEET']=df['GROSS SQUARE FEET'].fillna(df['GROSS SQUARE FEET'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset \n",
    "test=df[df['SALE PRICE'].isna()]\n",
    "data=df[~df['SALE PRICE'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns='SALE PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13909, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BUILDING CLASS CATEGORY</th>\n",
       "      <th>TAX CLASS AT PRESENT</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BUILDING CLASS AT PRESENT</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>APARTMENT NUMBER</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "      <th>BUILDING CLASS AT TIME OF SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>26</td>\n",
       "      <td>C7</td>\n",
       "      <td>234 EAST 4TH   STREET</td>\n",
       "      <td></td>\n",
       "      <td>10009</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>18690.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>39</td>\n",
       "      <td>C7</td>\n",
       "      <td>197 EAST 3RD   STREET</td>\n",
       "      <td></td>\n",
       "      <td>10009</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>7803.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>405</td>\n",
       "      <td>16</td>\n",
       "      <td>C4</td>\n",
       "      <td>516 EAST 12TH   STREET</td>\n",
       "      <td></td>\n",
       "      <td>10009</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>9730.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>407</td>\n",
       "      <td>18</td>\n",
       "      <td>C7</td>\n",
       "      <td>520 EAST 14TH   STREET</td>\n",
       "      <td></td>\n",
       "      <td>10009</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>5163.0</td>\n",
       "      <td>21007.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>08 RENTALS - ELEVATOR APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>379</td>\n",
       "      <td>34</td>\n",
       "      <td>D5</td>\n",
       "      <td>141 AVENUE D</td>\n",
       "      <td></td>\n",
       "      <td>10009</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>9198.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>2</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BOROUGH   NEIGHBORHOOD                      BUILDING CLASS CATEGORY  \\\n",
       "1       1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "2       1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "5       1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "7       1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "8       1  ALPHABET CITY  08 RENTALS - ELEVATOR APARTMENTS              \n",
       "\n",
       "  TAX CLASS AT PRESENT  BLOCK  LOT BUILDING CLASS AT PRESENT  \\\n",
       "1                    2    399   26                        C7   \n",
       "2                    2    399   39                        C7   \n",
       "5                    2    405   16                        C4   \n",
       "7                    2    407   18                        C7   \n",
       "8                    2    379   34                        D5   \n",
       "\n",
       "                  ADDRESS APARTMENT NUMBER  ZIP CODE  RESIDENTIAL UNITS  \\\n",
       "1   234 EAST 4TH   STREET                      10009                 28   \n",
       "2   197 EAST 3RD   STREET                      10009                 16   \n",
       "5  516 EAST 12TH   STREET                      10009                 20   \n",
       "7  520 EAST 14TH   STREET                      10009                 44   \n",
       "8            141 AVENUE D                      10009                 15   \n",
       "\n",
       "   COMMERCIAL UNITS  TOTAL UNITS  LAND SQUARE FEET  GROSS SQUARE FEET  \\\n",
       "1                 3           31            4616.0            18690.0   \n",
       "2                 1           17            2212.0             7803.0   \n",
       "5                 0           20            2581.0             9730.0   \n",
       "7                 2           46            5163.0            21007.0   \n",
       "8                 0           15            1534.0             9198.0   \n",
       "\n",
       "   YEAR BUILT TAX CLASS AT TIME OF SALE BUILDING CLASS AT TIME OF SALE  \n",
       "1        1900                         2                             C7  \n",
       "2        1900                         2                             C7  \n",
       "5        1900                         2                             C4  \n",
       "7        1900                         2                             C7  \n",
       "8        1920                         2                             D5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 5 rows of test\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as we have been dealt a huge dataset, outliers are to be expected. So, to handle this accordingly, first located the outliers by plotting them on a boxplot, and then filtered out appropriate variable ranges. Outliers can indicate errors in data collection but in the case of our data, errors in collecting data don't seem very probable.\n",
    "## Why is it important to remove outliers?\n",
    "Outliers can play a role in causing immense difficulties in the process of statistical analysis, as they represent a situation/scenario which is extremely unlikely to play out again. In the case of our dataset, outliers are entries in which massive amounts of total units are bought (example of this could be the sale of an apartment building, or a few floors thereof), which would have better fit our data if they were broken down entered as multiple sales of a smaller amount of units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are these visualizations below?\n",
    "These visualizations are to display all the different values in a specific column, and how far they are away from eachother compared to the aboslute minimum and maximum value. This is done using boxplot inside of the seaborn package. Here you just do seaborn.boxplot(x=dataframe[\"name of column you would like to display\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='SALE PRICE'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=data[\"SALE PRICE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TOTAL UNITS'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=data[\"TOTAL UNITS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows that contains outliers in both TOTAL UNITS and SALE PRICE. \n",
    "data = data[(data['TOTAL UNITS'] > 0) & (data['TOTAL UNITS'] < 1500)] \n",
    "data = data[(data['SALE PRICE'] > 100000) & (data['SALE PRICE'] < 5000000)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing that the outliers are removed from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='SALE PRICE'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=data[\"SALE PRICE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TOTAL UNITS'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=data[\"TOTAL UNITS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is pre-proccessing of dataset (Regression models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------\n",
    "# Why is apartment number and address getting dropped?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apartment number column is irrelevant, and removed due to the column being practically lacking half of its elements. Thus we simply do not have enough values to create a useful mean value to replace the empty slots with, as well as if we were to just leave it, the consequence would be alot of zero values which would greatly affect the price. The values are also lacking name consistency which also makes it harder to pre-process due to them being very different in value.\n",
    "\n",
    "We are dropping address due to the values lacking name consistency making it very hard to pre-process due to there being to many combinations of address names to make sensable pre-proccessing of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting some irrelevant columns!\n",
    "# Explanation above.\n",
    "\n",
    "del data['ADDRESS']\n",
    "del data['APARTMENT NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39003 entries, 3 to 84545\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   BOROUGH                         39003 non-null  category\n",
      " 1   NEIGHBORHOOD                    39003 non-null  object  \n",
      " 2   BUILDING CLASS CATEGORY         39003 non-null  object  \n",
      " 3   TAX CLASS AT PRESENT            39003 non-null  category\n",
      " 4   BLOCK                           39003 non-null  int64   \n",
      " 5   LOT                             39003 non-null  int64   \n",
      " 6   BUILDING CLASS AT PRESENT       39003 non-null  object  \n",
      " 7   ZIP CODE                        39003 non-null  int64   \n",
      " 8   RESIDENTIAL UNITS               39003 non-null  int64   \n",
      " 9   COMMERCIAL UNITS                39003 non-null  int64   \n",
      " 10  TOTAL UNITS                     39003 non-null  int64   \n",
      " 11  LAND SQUARE FEET                39003 non-null  float64 \n",
      " 12  GROSS SQUARE FEET               39003 non-null  float64 \n",
      " 13  YEAR BUILT                      39003 non-null  int64   \n",
      " 14  TAX CLASS AT TIME OF SALE       39003 non-null  category\n",
      " 15  BUILDING CLASS AT TIME OF SALE  39003 non-null  object  \n",
      " 16  SALE PRICE                      39003 non-null  float64 \n",
      "dtypes: category(3), float64(3), int64(7), object(4)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data=data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for skewness\n",
    "We check for skewness because we have in our dataset a large number of moderately priced houses, and some highly priced houses. this can be an indication that the data for specific values are skewed to the right side, which means you are predicting a much larger amount of moderately priced houses, and might cause the model to have a harder time predicitng the price for the more higher priced houses. \n",
    "\n",
    "One way to test this is by doing what is called Shapiro-Wilks test. the null hypotheses for this specific test is that the data is a sample from a normal distribution, so the p-value less than 0.05 indicates significant skewness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.7484854459762573, pvalue=0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(data[\"SALE PRICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of testing for skewness, is using pandas skew() method. it calculates the Fisher-Pearson standardized moment coefficient for all collumns in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <td>97.176872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <td>95.309583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <td>54.045558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <td>53.045021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <td>51.674276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOT</th>\n",
       "      <td>2.852163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SALE PRICE</th>\n",
       "      <td>2.308921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLOCK</th>\n",
       "      <td>0.921536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <td>-3.569420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP CODE</th>\n",
       "      <td>-5.006578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Skew\n",
       "LAND SQUARE FEET   97.176872\n",
       "COMMERCIAL UNITS   95.309583\n",
       "RESIDENTIAL UNITS  54.045558\n",
       "GROSS SQUARE FEET  53.045021\n",
       "TOTAL UNITS        51.674276\n",
       "LOT                 2.852163\n",
       "SALE PRICE          2.308921\n",
       "BLOCK               0.921536\n",
       "YEAR BUILT         -3.569420\n",
       "ZIP CODE           -5.006578"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "num_feats = data.dtypes[data.dtypes!=\"object\"].index\n",
    "skew_feats = data[num_feats].skew().sort_values(ascending=False)\n",
    "skewness=pd.DataFrame({\"Skew\":skew_feats})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming skewed data using log(x + 1)\n",
    "There is a way we can address skewed variables, and reduce the skewness of our current dataset. That way is by transforming them. This can be done by either including square root (sqrt(x)), logarithmic (log(x)) and reciprocal (1/x). For our data we have chosen to go the logarithmic route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the numeric features using log(x + 1)\n",
    "# skew is the degree of distortion from a normal distribution.\n",
    "# THe reason we chose to skew the data is so the models can predict the more expensive houses more accurately\n",
    "\n",
    "from scipy.stats import skew\n",
    "skewed = data[numeric_data.columns].apply(lambda x: skew(x.dropna().astype(float)))\n",
    "skewed = skewed[skewed > 0.75]\n",
    "skewed = skewed.index\n",
    "data[skewed] = np.log1p(data[skewed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SALE PRICE\"] = data[\"SALE PRICE\"]**(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9918535947799683, pvalue=8.906512909402105e-41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(data[\"SALE PRICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data for gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normality Check')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['SALE PRICE'])\n",
    "plt.title(\"Normality Check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(data['SALE PRICE'], ddof=1)\n",
    "mean = np.mean(data['SALE PRICE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why standardization and not normalization of data?\n",
    "Standarization a dataset involves rescaling the distribution of values so that the mean of observed is 0 and the standard deviation is 1. \n",
    "\n",
    "Standization can be very useful. and in some algorithms, it is even required. but standardization does assume that your observations fit a gaussian distribution. The data can still standardized even if these expectations are not met, but the results may not be as reliable. \n",
    "\n",
    "Compared to the figure you see under the title \"Checking data for gaussian distribution\" above this section, you can see that bell curve that signifies that the data fits a gaussian distribution. Therefor the standard scaler fits our project well as it standardizes our data instead of normalizing it. \n",
    "\n",
    "Had we not removed our outliers, we would have gone with the RobustScaler which works well with outliers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scaling data the numeric data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data[numeric_data.columns])\n",
    "scaled = scaler.transform(data[numeric_data.columns])\n",
    "\n",
    "for i, col in enumerate(numeric_data.columns):\n",
    "       data[col] = scaled[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping few columns that is not needed\n",
    "del data['BUILDING CLASS AT PRESENT']\n",
    "del data['BUILDING CLASS AT TIME OF SALE']\n",
    "del data['NEIGHBORHOOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the variables to be one-hot encoded\n",
    "# We one hot encode this data so that the models can predict more accurately given the data they have. \n",
    "one_hot_features = ['BOROUGH', 'BUILDING CLASS CATEGORY','TAX CLASS AT PRESENT','TAX CLASS AT TIME OF SALE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we one-hot encode the different categorical columns? \n",
    "A one-hot encoding allows for more expressive categorical data representation. Many machine learning algorithms are unable to work directly with categorical data. The categories must be numerically converted. This is required for categorical input and output variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under here we are one-hot encoding categorical columns\n",
    "\n",
    "One-hot encoding is practically a way of representing categorical variables binary vectors, this also requires the categorical data has been mapped in to integer values, or else you will get an error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39003 entries, 3 to 84545\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                                                Non-Null Count  Dtype\n",
      "---  ------                                                                --------------  -----\n",
      " 0   BOROUGH_1                                                             39003 non-null  uint8\n",
      " 1   BOROUGH_2                                                             39003 non-null  uint8\n",
      " 2   BOROUGH_3                                                             39003 non-null  uint8\n",
      " 3   BOROUGH_4                                                             39003 non-null  uint8\n",
      " 4   BOROUGH_5                                                             39003 non-null  uint8\n",
      " 5   BUILDING CLASS CATEGORY_01 ONE FAMILY DWELLINGS                       39003 non-null  uint8\n",
      " 6   BUILDING CLASS CATEGORY_02 TWO FAMILY DWELLINGS                       39003 non-null  uint8\n",
      " 7   BUILDING CLASS CATEGORY_03 THREE FAMILY DWELLINGS                     39003 non-null  uint8\n",
      " 8   BUILDING CLASS CATEGORY_04 TAX CLASS 1 CONDOS                         39003 non-null  uint8\n",
      " 9   BUILDING CLASS CATEGORY_05 TAX CLASS 1 VACANT LAND                    39003 non-null  uint8\n",
      " 10  BUILDING CLASS CATEGORY_06 TAX CLASS 1 - OTHER                        39003 non-null  uint8\n",
      " 11  BUILDING CLASS CATEGORY_07 RENTALS - WALKUP APARTMENTS                39003 non-null  uint8\n",
      " 12  BUILDING CLASS CATEGORY_08 RENTALS - ELEVATOR APARTMENTS              39003 non-null  uint8\n",
      " 13  BUILDING CLASS CATEGORY_09 COOPS - WALKUP APARTMENTS                  39003 non-null  uint8\n",
      " 14  BUILDING CLASS CATEGORY_10 COOPS - ELEVATOR APARTMENTS                39003 non-null  uint8\n",
      " 15  BUILDING CLASS CATEGORY_11A CONDO-RENTALS                             39003 non-null  uint8\n",
      " 16  BUILDING CLASS CATEGORY_12 CONDOS - WALKUP APARTMENTS                 39003 non-null  uint8\n",
      " 17  BUILDING CLASS CATEGORY_13 CONDOS - ELEVATOR APARTMENTS               39003 non-null  uint8\n",
      " 18  BUILDING CLASS CATEGORY_14 RENTALS - 4-10 UNIT                        39003 non-null  uint8\n",
      " 19  BUILDING CLASS CATEGORY_15 CONDOS - 2-10 UNIT RESIDENTIAL             39003 non-null  uint8\n",
      " 20  BUILDING CLASS CATEGORY_16 CONDOS - 2-10 UNIT WITH COMMERCIAL UNIT    39003 non-null  uint8\n",
      " 21  BUILDING CLASS CATEGORY_21 OFFICE BUILDINGS                           39003 non-null  uint8\n",
      " 22  BUILDING CLASS CATEGORY_22 STORE BUILDINGS                            39003 non-null  uint8\n",
      " 23  BUILDING CLASS CATEGORY_23 LOFT BUILDINGS                             39003 non-null  uint8\n",
      " 24  BUILDING CLASS CATEGORY_26 OTHER HOTELS                               39003 non-null  uint8\n",
      " 25  BUILDING CLASS CATEGORY_27 FACTORIES                                  39003 non-null  uint8\n",
      " 26  BUILDING CLASS CATEGORY_28 COMMERCIAL CONDOS                          39003 non-null  uint8\n",
      " 27  BUILDING CLASS CATEGORY_29 COMMERCIAL GARAGES                         39003 non-null  uint8\n",
      " 28  BUILDING CLASS CATEGORY_30 WAREHOUSES                                 39003 non-null  uint8\n",
      " 29  BUILDING CLASS CATEGORY_31 COMMERCIAL VACANT LAND                     39003 non-null  uint8\n",
      " 30  BUILDING CLASS CATEGORY_32 HOSPITAL AND HEALTH FACILITIES             39003 non-null  uint8\n",
      " 31  BUILDING CLASS CATEGORY_33 EDUCATIONAL FACILITIES                     39003 non-null  uint8\n",
      " 32  BUILDING CLASS CATEGORY_35 INDOOR PUBLIC AND CULTURAL FACILITIES      39003 non-null  uint8\n",
      " 33  BUILDING CLASS CATEGORY_37 RELIGIOUS FACILITIES                       39003 non-null  uint8\n",
      " 34  BUILDING CLASS CATEGORY_38 ASYLUMS AND HOMES                          39003 non-null  uint8\n",
      " 35  BUILDING CLASS CATEGORY_41 TAX CLASS 4 - OTHER                        39003 non-null  uint8\n",
      " 36  BUILDING CLASS CATEGORY_42 CONDO CULTURAL/MEDICAL/EDUCATIONAL/ETC     39003 non-null  uint8\n",
      " 37  BUILDING CLASS CATEGORY_43 CONDO OFFICE BUILDINGS                     39003 non-null  uint8\n",
      " 38  BUILDING CLASS CATEGORY_44 CONDO PARKING                              39003 non-null  uint8\n",
      " 39  BUILDING CLASS CATEGORY_45 CONDO HOTELS                               39003 non-null  uint8\n",
      " 40  BUILDING CLASS CATEGORY_46 CONDO STORE BUILDINGS                      39003 non-null  uint8\n",
      " 41  BUILDING CLASS CATEGORY_47 CONDO NON-BUSINESS STORAGE                 39003 non-null  uint8\n",
      " 42  BUILDING CLASS CATEGORY_48 CONDO TERRACES/GARDENS/CABANAS             39003 non-null  uint8\n",
      " 43  TAX CLASS AT PRESENT_                                                 39003 non-null  uint8\n",
      " 44  TAX CLASS AT PRESENT_1                                                39003 non-null  uint8\n",
      " 45  TAX CLASS AT PRESENT_1A                                               39003 non-null  uint8\n",
      " 46  TAX CLASS AT PRESENT_1B                                               39003 non-null  uint8\n",
      " 47  TAX CLASS AT PRESENT_1C                                               39003 non-null  uint8\n",
      " 48  TAX CLASS AT PRESENT_2                                                39003 non-null  uint8\n",
      " 49  TAX CLASS AT PRESENT_2A                                               39003 non-null  uint8\n",
      " 50  TAX CLASS AT PRESENT_2B                                               39003 non-null  uint8\n",
      " 51  TAX CLASS AT PRESENT_2C                                               39003 non-null  uint8\n",
      " 52  TAX CLASS AT PRESENT_3                                                39003 non-null  uint8\n",
      " 53  TAX CLASS AT PRESENT_4                                                39003 non-null  uint8\n",
      " 54  TAX CLASS AT TIME OF SALE_1                                           39003 non-null  uint8\n",
      " 55  TAX CLASS AT TIME OF SALE_2                                           39003 non-null  uint8\n",
      " 56  TAX CLASS AT TIME OF SALE_3                                           39003 non-null  uint8\n",
      " 57  TAX CLASS AT TIME OF SALE_4                                           39003 non-null  uint8\n",
      "dtypes: uint8(58)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded = pd.get_dummies(data[one_hot_features])\n",
    "one_hot_encoded.info(verbose=True, memory_usage=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing categorical columns with dummies\n",
    "fdf = data.drop(one_hot_features,axis=1)\n",
    "fdf = pd.concat([fdf, one_hot_encoded] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39003, 67), (39003,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing dataset in to Data and Target values.\n",
    "\n",
    "Y_fdf = fdf['SALE PRICE']\n",
    "X_fdf = fdf.drop('SALE PRICE', axis=1)\n",
    "\n",
    "X_fdf.shape , Y_fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset in to a test set and a training set\n",
    "\n",
    "X_train ,X_test, Y_train , Y_test = train_test_split(X_fdf , Y_fdf , test_size = 0.3 , random_state =34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reason for using RMSE instead of just R2. \n",
    "\n",
    "R-squared is conventiently scaled between 0 and 1, whereas RMSE is not scaled to any particular values. This can be good or bad; obviously R-squared can be more easily interpreted, but with RMSE we explcitly know how much our predictions deviate, on average, from the actual values in the dataset. So in a way, RMSE tells you more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a RMSE\n",
    "# Lower Score = Better Score. Lower > Higher.\n",
    "def rmse(y_test,y_pred):\n",
    "      return np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the Regression models we have chosen for our project. \n",
    "- Support Vector Machine (SVM)\n",
    "- K Neighbor Regressor\n",
    "- Random Forest Regressor\n",
    "- Decision Tree Regressor\n",
    "- Multi Layer Perceptron Regressor (MLPR)(Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "The Support Vector Machine (or SVM) is a linear classifier. The SVM will take in data points, and compute the best \"Hyperplane\", a line which seperates data into their respective classes. This hyperplane is computed based on the margin between the line and closest data point of that class. It seeks to maximize this margin, and be as far away from the datapoints of each class as possible.\n",
    "\n",
    "We use the Support Vector Regressor from the svm package, which uses generally the same principles, with only a few differences. As output is a real number, prediction becomes difficult. As a result of these difficulties, a margin of tolerance is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "supportvectormachine = svm.SVR(C=1)\n",
    "supportvectormachine.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "gsc = GridSearchCV(\n",
    "        estimator=SVR(kernel='rbf'),\n",
    "        param_grid={\n",
    "            'C': [0.1, 1, 100, 1000],\n",
    "            'epsilon': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 308 candidates, totalling 1540 fits\n"
     ]
    }
   ],
   "source": [
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_svr = SVR(kernel='rbf', C=best_params[\"C\"], epsilon=best_params[\"epsilon\"], gamma=best_params[\"gamma\"],\n",
    "                   coef0=0.1, shrinking=True,\n",
    "                   tol=0.001, cache_size=200, verbose=2, max_iter=-1)\n",
    "#Verbose = 2 *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'C': 1, 'epsilon': 0.1, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"best params\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02171121, -0.44915881, -2.49490954, ...,  0.43039892,\n",
       "       -1.01373686, -0.12033419])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = supportvectormachine.predict(X_test)\n",
    "# predictions = scaler.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66559413,  1.20167382, -1.40917184, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.45698758,  1.37057494,  0.73010031, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.13351184, -0.03307239,  0.86028892, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.26910378, -0.44199277,  0.73170757, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00748847, -1.28209168, -0.95913713, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.22937614, -1.28209168,  0.50026115, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supportvectormachine.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     4, ..., 27299, 27300, 27301])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supportvectormachine.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5617892680452916\n",
      "RMSE Score: 0.6574965275058103\n"
     ]
    }
   ],
   "source": [
    "print(supportvectormachine.score(X_test, Y_test))\n",
    "print(f\"RMSE Score: {rmse(Y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbors Regressor\n",
    "The score on this model was fairly low as KNearest models does not work that well on big datasets, we decided to include it anyways as it is just as important to analyze a method in suboptimal conditions as it is to study it in optimal conditions.\n",
    "\n",
    "K Nearest Neighbors Regression is a non-parametric method that seeks to estimate the association between independent variables and continuous outcomes by averaging observations in their respective neighborhoods. Therefore, the analyst must determine the neighborhood size, K. We found that a K value of 8 best suited our intentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "kneighborsregressor = KNeighborsRegressor(n_neighbors=8)\n",
    "kneighborsregressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01862627, -0.47499111, -2.45790048, ...,  0.3838277 ,\n",
       "       -1.16435619, -0.48851349])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = kneighborsregressor.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighborsregressor.kneighbors_graph(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6296250473768397\n",
      "RMSE Score: 0.604467232565021\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 Score: {kneighborsregressor.score(X_test, Y_test)}\")\n",
    "print(f\"RMSE Score: {rmse(Y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor\n",
    "Loosely; a random forest regressor constructs several decision trees, then outputs the mean of the classes as the prediction of all the trees. Although random forest regressors are powerful and accurate, and work well in a wide range of cases, there is no interpretability, and we must be vigilant towards overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score: 0.6550874339171374\n",
      "R2 Score: 0.5649946282999401\n"
     ]
    }
   ],
   "source": [
    "rf_regr = RandomForestRegressor(criterion=\"mse\", n_estimators=1000, max_features=\"sqrt\", \n",
    "                               n_jobs=-1, random_state=1234)\n",
    "rf_regr.fit(X_train, Y_train)\n",
    "Y_pred_rf = rf_regr.predict(X_test)\n",
    "print(f\"RMSE Score: {rmse(Y_test,Y_pred_rf)}\")\n",
    "print(f\"R2 Score: {rf_regr.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree regressor\n",
    "A good way to visualize a decision tree, is to visualize it as a serious of questions that is asked about the input data, each question eliminating possible values until the model is confident enough to reach a conclusion. It is important to note that all questions asked to the input data are formed in True/False manner.\n",
    "First, the model is trained with relevant historical data. The model then calculates appropriate questions, and question order, based on an analysis it does on the relationships between the data and the target variable (These calculations can be done by hand with a metric like gini impurity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score: 0.7470789465530165\n",
      "R2 Score: 0.4342441180333222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(criterion=\"friedman_mse\")\n",
    "dtr.fit(X_train, Y_train)\n",
    "pred = dtr.predict(X_test)\n",
    "print(f\"RMSE Score: {rmse(Y_test, pred)}\")\n",
    "print(f\"R2 Score: {dtr.score(X_test, Y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs Decision Tree\n",
    "In our different tree models, which was decision tree regressor and a random forest regressor. in our models, our random forest regressor clearly beat our decision tree regressor by quite a mark. here are the results\n",
    "\n",
    "Decision Tree R2: 0.42\n",
    "Decision Tree RMSE: 0.75\n",
    "\n",
    "Random Forest R2: 0.68\n",
    "Random Forest RMSE: 0.55\n",
    "\n",
    "When it comes to comparing these models, random forest leverages the power of multiple decision trees, instead of relying on feaure importance given by a single decision tree. Random forest also chooses features randomly during the training process, which is a special characterstic of random forrest over bagging tree's, which is a variance of a decision tree where the goal is to reduce the variance of a decision tree.\n",
    "\n",
    "Since random forest uses more tree's, it will take longer to train the data, as it has to train each individual tree, which will increase the time taken by AmountOfTrees(x), while decision trees focuses more on speed due to only having to train one decision tree.  \n",
    "\n",
    "We can also see that the decision tree deviate further away from the correct answer on avarage, as shown in the RMSE score on both parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Multi Layer Perceptron Regressor (Without Hyper Parameter Tuning)\n",
    "A Multi Layer Perceptron, is like a perceptron in the sense that it has an input layer and output layer which are connected, but an MLP can have many hidden layers in between the input and output layer. In forward passing, the input flows from the input layer through all the hidden layers and then to the output layer, where a decision is made and measured against the ground truth labels. Essentially, the multilayer perceptron is just a series of perceptron algorithms, a neural network. Each layer (perceptron) will multiply with weights and add bias, to come to a conclusion.\n",
    "\n",
    "# Solver Paramter Explanation (adam)\n",
    "We chose the optimization algorithm adam. the reason we chose it, is because it has little memory requirements, it is computationally efficient, as well as it is well suited for problems that are large in terms of data and/or paramters. and in our dataset, we have a quite large dataset to work with, therefor adam works well in our case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.5943961823384292\n",
      "RMSE Score: 0.6325618206955922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor \n",
    "mlpregressor = MLPRegressor(random_state=1, max_iter=400, solver=\"adam\")\n",
    "mlpregressor.fit(X_train,Y_train)\n",
    "\n",
    "print(\"R2 Score:\",mlpregressor.score(X_test, Y_test))\n",
    "predictions = mlpregressor.predict(X_test)\n",
    "print(f\"RMSE Score: {rmse(Y_test, predictions)}\")\n",
    "\n",
    "# CODE WONT BE EXECUTED; SO WHEN YOU RUN THIS PART. STOP THE KERNAL WHEN YOU HAVE RAN IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing A version of hyper parameter tuning to find the best possible parameters for the MLPRegressor\n",
    "We are using sklearns inbuilt package called GridSearchCV, which does grid search including an x amount of cross validations that can be set in the parameters. we do this to test all the different combinations of parameters to check which parameters is giving us our best score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_parameters = {\n",
    "    'hidden_layer_sizes': [(50,50), (100,50), (150, 100), (12, 6)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gridsearchcv = GridSearchCV(mlpregressor, check_parameters, n_jobs=-1, cv=3)\n",
    "    gridsearchcv.fit(X_train, Y_train)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"You stopped the program, therefor it is not running anymore\")\n",
    "    \n",
    "# THIS TAKES OVER 30 MINUTES TO COMPLETE, SO DO NOT RUN THIS LINE; NOR THE ONE BELOW\n",
    "\n",
    "# Here is the output for the line below:  {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50),\n",
    "#'learning_rate': 'constant', 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant'}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:\\n', gridsearchcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPRegressor with Hyper Parameter Tuning applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6205151346076112\n",
      "RMSE score: 0.6325618206955922\n"
     ]
    }
   ],
   "source": [
    "mlpregressor = MLPRegressor(random_state=1, max_iter=400, activation='tanh', alpha=0.0001, hidden_layer_sizes=(150, 100), \n",
    "                           learning_rate = \"constant\", solver = \"adam\")\n",
    "mlpregressor.fit(X_train,Y_train)\n",
    "\n",
    "print(\"R2 Score:\",mlpregressor.score(X_test, Y_test))\n",
    "print(f\"RMSE score: {rmse(Y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
